# TODO Check if docker is gpu capable
- name: check if gpu capable
  stat:
    path: /.dockerenv
  register: docker

- name: Install dependencies
  apt:
    name:
      - git
      - python-apt
      - python-setuptools
      - python-pip
      - python-wheel
      - python

- include_tasks: "cuda.yml"
  when: not docker.stat.exists

- name: Clone tensorflow project containing models scripts
  git:
    repo: 'https://github.com/tensorflow/models.git'
    dest: /tmp/models
    version: v{{ tf_model_version }}

- name: Install specific tensorflow GPU release
  pip:
    name: tensorflow-gpu=={{ tf_version }}
  when: not docker.stat.exists

- name: Install specific tensorflow release
  pip:
    name: tensorflow=={{ tf_version }}
  when: docker.stat.exists

- name: Install project deps
  pip:
    requirements: /tmp/models/official/requirements.txt

- name: Run mnist # noqa 301
  command: "{{ run_cmd }}"
  args:
    chdir: "/tmp/models/{{ run_dir }}"
  environment:
    LD_LIBRARY_PATH: "/usr/local/cuda-{{ cuda_dot }}/lib64"
    PYTHONPATH: /tmp/models
  register: mnist

- name: collect stdout logs from run
  copy: content="{{ mnist.stdout }}" dest="{{ config_dir }}/{{ inventory_hostname }}-mnist.out.log"
  become: false
  delegate_to: localhost

- name: collect stderr logs from run
  copy: content="{{ mnist.stderr }}" dest="{{ config_dir }}/{{ inventory_hostname }}-mnist.err.log"
  become: false
  delegate_to: localhost
